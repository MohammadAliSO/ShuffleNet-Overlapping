{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqZ7F-q5A6lc"
      },
      "outputs": [],
      "source": [
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eROuxkNu4TAb",
        "outputId": "ecdee530-e2b5-4211-e00f-e1170a8445f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie4co-P6Pdk7"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/DataSets/dog&cat/train.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Mx_q8L44SHd"
      },
      "source": [
        "### build network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KKYDKMk4SHe"
      },
      "outputs": [],
      "source": [
        "overlap_size = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJs2QCkA9umU"
      },
      "outputs": [],
      "source": [
        "def channel_shuffle(x, groups=2):\n",
        "  bat_size, channels, w, h = x.shape\n",
        "  group_c = channels // groups\n",
        "  x = x.view(bat_size, groups, group_c, w, h)\n",
        "  x = t.transpose(x, 1, 2).contiguous()\n",
        "  x = x.view(bat_size, -1, w, h)\n",
        "  return x\n",
        "\n",
        "# used in the block\n",
        "def conv_1x1_bn(in_c, out_c, stride=1):\n",
        "  return nn.Sequential(\n",
        "    nn.Conv2d(in_c, out_c, 1, stride, 0, bias=False),\n",
        "    nn.BatchNorm2d(out_c),\n",
        "    nn.ReLU(True)\n",
        "  )\n",
        "\n",
        "def conv_bn(in_c, out_c, stride=2):\n",
        "  return nn.Sequential(\n",
        "    nn.Conv2d(in_c, out_c, 3, stride, 1, bias=False),\n",
        "    nn.BatchNorm2d(out_c),\n",
        "    nn.ReLU(True)\n",
        "  )\n",
        "\n",
        "\n",
        "class ShuffleBlock(nn.Module):\n",
        "  def __init__(self, in_c, out_c, downsample=False):\n",
        "    super(ShuffleBlock, self).__init__()\n",
        "    self.downsample = downsample\n",
        "    half_c = out_c // 2\n",
        "    input_overlap = (overlap_size*2)\n",
        "    input_with_overlap = (half_c-overlap_size)\n",
        "\n",
        "    if downsample:\n",
        "      self.branch1 = nn.Sequential(\n",
        "          # 3*3 dw conv, stride = 2\n",
        "          nn.Conv2d(in_c, in_c, 3, 2, 1, groups=in_c, bias=False),\n",
        "          nn.BatchNorm2d(in_c),\n",
        "          # 1*1 pw conv\n",
        "          nn.Conv2d(in_c, half_c, 1, 1, 0, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          nn.ReLU(True)\n",
        "      )\n",
        "\n",
        "      self.branch2 = nn.Sequential(\n",
        "          # 1*1 pw conv\n",
        "          nn.Conv2d(in_c, half_c, 1, 1, 0, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          nn.ReLU(True),\n",
        "          # 3*3 dw conv, stride = 2\n",
        "          nn.Conv2d(half_c, half_c, 3, 2, 1, groups=half_c, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          # 1*1 pw conv\n",
        "          nn.Conv2d(half_c, half_c, 1, 1, 0, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          nn.ReLU(True)\n",
        "      )\n",
        "\n",
        "      self.branch_overlaping = nn.Sequential(\n",
        "          # 3*3 dw conv, stride = 2\n",
        "          nn.Conv2d(in_c, in_c, 3, 2, 1, groups=in_c, bias=False),\n",
        "          nn.BatchNorm2d(in_c),\n",
        "          # 1*1 pw conv\n",
        "          nn.Conv2d(in_c, half_c, 1, 1, 0, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          nn.ReLU(True)\n",
        "      )\n",
        "\n",
        "    else:\n",
        "      # in_c = out_c\n",
        "      assert in_c == out_c\n",
        "\n",
        "      self.branch1 = nn.Sequential(\n",
        "          # 1*1 pw conv\n",
        "          nn.Conv2d(input_with_overlap, half_c, 1, 1, 0, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          nn.ReLU(True)\n",
        "      )\n",
        "\n",
        "      self.branch2 = nn.Sequential(\n",
        "          # 1*1 pw conv\n",
        "          nn.Conv2d(input_with_overlap, half_c, 1, 1, 0, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          nn.ReLU(True),\n",
        "          # 3*3 dw conv, stride = 1\n",
        "          nn.Conv2d(half_c, half_c, 3, 1, 1, groups=half_c, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          # # 1*1 pw conv\n",
        "          # nn.Conv2d(half_c, half_c, 1, 1, 0, bias=False),\n",
        "          # nn.BatchNorm2d(half_c),\n",
        "          # nn.ReLU(True)\n",
        "      )\n",
        "\n",
        "      self.branch_overlaping = nn.Sequential(\n",
        "          # 1*1 pw conv\n",
        "          nn.Conv2d(input_overlap, half_c, 1, 1, 0, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          nn.ReLU(True),\n",
        "          # 3*3 dw conv, stride = 1\n",
        "          nn.Conv2d(half_c, half_c, 3, 1, 1, groups=half_c, bias=False),\n",
        "          nn.BatchNorm2d(half_c),\n",
        "          # # 1*1 pw conv\n",
        "          # nn.Conv2d(half_c, half_c, 1, 1, 0, bias=False),\n",
        "          # nn.BatchNorm2d(half_c),\n",
        "          # nn.ReLU(True)\n",
        "      )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = None\n",
        "    if self.downsample:\n",
        "      # if it is downsampling, we don't need to do channel split\n",
        "      branch1_with_overlap= t.add(self.branch1(x) , self.branch_overlaping(x))\n",
        "      branch2_with_overlap= t.add(self.branch2(x) , self.branch_overlaping(x))\n",
        "      out = t.cat((branch1_with_overlap, branch2_with_overlap), 1)\n",
        "    else:\n",
        "      # channel split\n",
        "      channels = x.shape[1]\n",
        "      c = channels // 2\n",
        "\n",
        "      x1 = x[:, :(c-overlap_size), :, :]\n",
        "      x_overlap = x[:, (c-overlap_size):(c+overlap_size), :, :]\n",
        "      x2 = x[:, (c+overlap_size):, :, :]\n",
        "\n",
        "      branch1 = self.branch1(x1)\n",
        "      branch2 = self.branch2(x2)\n",
        "      branch_overlap = self.branch_overlaping(x_overlap)\n",
        "\n",
        "      branch1_with_overlap= t.add( branch1 , branch_overlap)\n",
        "      branch2_with_overlap= t.add(branch2 , branch_overlap)\n",
        "\n",
        "      out = t.cat((branch1_with_overlap, branch2_with_overlap), 1)\n",
        "    return channel_shuffle(out, 2)\n",
        "\n",
        "\n",
        "class ShuffleNet2(nn.Module):\n",
        "  def __init__(self, num_classes=2, input_size=224, net_type=1):\n",
        "    super(ShuffleNet2, self).__init__()\n",
        "    assert input_size % 32 == 0 # 因为一共会下采样32倍\n",
        "\n",
        "\n",
        "    self.stage_repeat_num = [4, 8, 4]\n",
        "    if net_type == 0.5:\n",
        "      self.out_channels = [3, 24, 48, 96, 192, 1024]\n",
        "    elif net_type == 1:\n",
        "      self.out_channels = [3, 24, 116, 232, 464, 1024]\n",
        "    elif net_type == 1.5:\n",
        "      self.out_channels = [3, 24, 176, 352, 704, 1024]\n",
        "    elif net_type == 2:\n",
        "      self.out_channels = [3, 24, 244, 488, 976, 2948]\n",
        "    else:\n",
        "      print(\"the type is error, you should choose 0.5, 1, 1.5 or 2\")\n",
        "\n",
        "    # let's start building layers\n",
        "    self.conv1 = nn.Conv2d(3, self.out_channels[1], 3, 2, 1)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    in_c = self.out_channels[1]\n",
        "\n",
        "    self.stages = []\n",
        "    for stage_idx in range(len(self.stage_repeat_num)):\n",
        "      out_c = self.out_channels[2+stage_idx]\n",
        "      repeat_num = self.stage_repeat_num[stage_idx]\n",
        "      print(f\"in_c:{in_c} out_c:{out_c} repeat_num:{repeat_num}\")\n",
        "      for i in range(repeat_num):\n",
        "        if i == 0:\n",
        "          self.stages.append(ShuffleBlock(in_c, out_c, downsample=True))\n",
        "        else:\n",
        "          self.stages.append(ShuffleBlock(in_c, in_c, downsample=False))\n",
        "        in_c = out_c\n",
        "    self.stages = nn.Sequential(*self.stages)\n",
        "\n",
        "    in_c = self.out_channels[-2]\n",
        "    out_c = self.out_channels[-1]\n",
        "    self.conv5 = conv_1x1_bn(in_c, out_c, 1)\n",
        "    self.g_avg_pool = nn.AvgPool2d(kernel_size=(int)(input_size/32)) # 如果输入的是224，则此处为7\n",
        "\n",
        "    # fc layer\n",
        "    self.fc = nn.Linear(out_c, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.stages(x)\n",
        "    x = self.conv5(x)\n",
        "    x = self.g_avg_pool(x)\n",
        "    x = x.view(-1, self.out_channels[-1])\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "import os\n",
        "import time\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import copy"
      ],
      "metadata": {
        "id": "l638v8zsk4_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DogCat(data.Dataset):\n",
        "  def __init__(self, root, trans=None, train=True, test=False):\n",
        "    self.test = test\n",
        "    self.train = train\n",
        "    imgs = [os.path.join(root, img) for img in os.listdir(root)]\n",
        "    '''\n",
        "    the format of test and trian image name is different\n",
        "    as for test: /test/102.jpg\n",
        "    as for train: /train/cat.1.jpg\n",
        "    '''\n",
        "    if test: # root: './dogvscat/test/' imgs = [\"xx/123.jpg\", \"xx/234.jpg\", ...]\n",
        "      sorted(imgs, key=lambda x: int(x.split(\".\")[-2].split(\"/\")[-1]))\n",
        "    else:\n",
        "      sorted(imgs, key=lambda x: int(x.split(\".\")[-2]))\n",
        "\n",
        "    # shuffle\n",
        "    np.random.seed(100)\n",
        "    imgs = np.random.permutation(imgs)\n",
        "\n",
        "    # split dataset\n",
        "    if self.test:\n",
        "      self.imgs = imgs\n",
        "    elif train:\n",
        "      self.imgs = imgs[:int(0.7*len(imgs))]\n",
        "    else:\n",
        "      self.imgs = imgs[int(0.7*len(imgs)):]\n",
        "\n",
        "    if trans==None:\n",
        "      normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                        std=[0.229, 0.224, 0.225])\n",
        "      # test and dev dataset do not need to do data augemetation\n",
        "      if self.test or not self.train:\n",
        "        self.trans = transforms.Compose([\n",
        "                                        transforms.Resize(224),\n",
        "                                        transforms.CenterCrop(224),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        normalize\n",
        "                                        ])\n",
        "      else:\n",
        "        self.trans = transforms.Compose([\n",
        "                                        transforms.Resize(256),\n",
        "                                        transforms.CenterCrop(224), # RandomSizedCrop(224)??\n",
        "                                        transforms.RandomHorizontalFlip(),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        normalize\n",
        "                                        ])\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    '''\n",
        "    as for test: just return the id of picture.\n",
        "    as for train and dev: return 1 if dog, return 0 if cat\n",
        "    '''\n",
        "    imgpath = self.imgs[index]\n",
        "    if self.test:\n",
        "      label = int(imgpath.split(\".\")[-2].split(\"/\")[-1])\n",
        "    else:\n",
        "      kind = imgpath.split(\".\")[-3].split(\"/\")[-1]\n",
        "      label = 1 if kind == \"dog\" else 0\n",
        "    img = Image.open(imgpath)\n",
        "    img = self.trans(img)\n",
        "    return img, label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs)"
      ],
      "metadata": {
        "id": "PNIIE5O9k6db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_result = []\n",
        "train_result = []"
      ],
      "metadata": {
        "id": "5c5pszZ0lHux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f\"Period {i}\")\n",
        "  model = ShuffleNet2()\n",
        "  device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
        "  model = model.to(device)\n",
        "\n",
        "\n",
        "  train_dataset = DogCat(\"/content/train\", train=True)\n",
        "  val_dataset = DogCat(\"/content/train\", train=False, test=False)\n",
        "  train_loader = data.DataLoader(train_dataset,\n",
        "                                 batch_size = 32,\n",
        "                                 shuffle=True\n",
        "                                 )\n",
        "  val_loader = data.DataLoader(val_dataset,\n",
        "                               batch_size = 32,\n",
        "                               shuffle=True)\n",
        "\n",
        "  dataloader = {}\n",
        "  dataloader[\"train\"] = train_loader\n",
        "  dataloader[\"val\"] = val_loader\n",
        "\n",
        "  device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
        "  model = ShuffleNet2()\n",
        "  model = model.to(device)\n",
        "\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  optimizer = t.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "\n",
        "\n",
        "  def train_model(model, dataloaders, loss_fn, optimizer, num_epochs=5):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.\n",
        "    val_loss_history = []\n",
        "    train_loss_history = []\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in [\"train\", \"val\"]:\n",
        "            running_loss = 0.\n",
        "            running_corrects = 0.\n",
        "            if phase == \"train\":\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                with t.autograd.set_grad_enabled(phase==\"train\"):\n",
        "                    outputs = model(inputs) # bsize * 2 , because it is a binary classification\n",
        "                    loss = loss_fn(outputs, labels)\n",
        "\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                if phase == \"train\":\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += t.sum(preds.view(-1) == labels.view(-1)).item()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print(\"Phase {} loss: {}, acc: {}\".format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == \"val\" and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == \"val\":\n",
        "                val_loss_history.append(epoch_acc)\n",
        "            if(phase == \"train\"):\n",
        "                train_loss_history.append(epoch_acc)\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_loss_history , train_loss_history\n",
        "\n",
        "  model, val_logs , train_logs = train_model(model, dataloader, loss_fn, optimizer)\n",
        "  val_result.append(val_logs[-1])\n",
        "  train_result.append(train_logs[-1])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKyG1qp7lKOl",
        "outputId": "3fe14b2b-53b8-438f-9ac4-acdada3c6bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Period 0\n",
            "in_c:24 out_c:116 repeat_num:4\n",
            "in_c:116 out_c:232 repeat_num:8\n",
            "in_c:232 out_c:464 repeat_num:4\n",
            "in_c:24 out_c:116 repeat_num:4\n",
            "in_c:116 out_c:232 repeat_num:8\n",
            "in_c:232 out_c:464 repeat_num:4\n",
            "Phase train loss: 0.8029001598903112, acc: 0.5082285714285715\n",
            "Phase val loss: 0.6887243152618409, acc: 0.5249333333333334\n",
            "Phase train loss: 0.6910956351416452, acc: 0.5213142857142857\n",
            "Phase val loss: 0.6877228557268779, acc: 0.5433333333333333\n",
            "Phase train loss: 0.6816616611208235, acc: 0.5578857142857143\n",
            "Phase val loss: 0.66035838098526, acc: 0.5997333333333333\n",
            "Phase train loss: 0.6368497250011989, acc: 0.6397714285714285\n",
            "Phase val loss: 0.607638019212087, acc: 0.6818666666666666\n",
            "Phase train loss: 0.564117007786887, acc: 0.7112\n",
            "Phase val loss: 0.6086535639444987, acc: 0.7032\n",
            "Period 1\n",
            "in_c:24 out_c:116 repeat_num:4\n",
            "in_c:116 out_c:232 repeat_num:8\n",
            "in_c:232 out_c:464 repeat_num:4\n",
            "in_c:24 out_c:116 repeat_num:4\n",
            "in_c:116 out_c:232 repeat_num:8\n",
            "in_c:232 out_c:464 repeat_num:4\n",
            "Phase train loss: 0.7652605025018965, acc: 0.5948\n",
            "Phase val loss: 0.6285866210619608, acc: 0.6497333333333334\n",
            "Phase train loss: 0.5879168344361442, acc: 0.6922285714285714\n",
            "Phase val loss: 0.5492106637795766, acc: 0.7313333333333333\n",
            "Phase train loss: 0.5259021003586906, acc: 0.7460571428571429\n",
            "Phase val loss: 0.5399645852088928, acc: 0.7265333333333334\n",
            "Phase train loss: 0.4731216697760991, acc: 0.7778285714285714\n",
            "Phase val loss: 0.5058412593841553, acc: 0.7534666666666666\n",
            "Phase train loss: 0.435183582169669, acc: 0.7994857142857142\n",
            "Phase val loss: 0.4711459084669749, acc: 0.7789333333333334\n",
            "Period 2\n",
            "in_c:24 out_c:116 repeat_num:4\n",
            "in_c:116 out_c:232 repeat_num:8\n",
            "in_c:232 out_c:464 repeat_num:4\n",
            "in_c:24 out_c:116 repeat_num:4\n",
            "in_c:116 out_c:232 repeat_num:8\n",
            "in_c:232 out_c:464 repeat_num:4\n",
            "Phase train loss: 0.8346626458304269, acc: 0.5049714285714286\n",
            "Phase val loss: 0.7018246825218201, acc: 0.49773333333333336\n",
            "Phase train loss: 0.6905289146014623, acc: 0.5338857142857143\n",
            "Phase val loss: 0.6638038342157999, acc: 0.6029333333333333\n",
            "Phase train loss: 0.6240505317960466, acc: 0.6590285714285714\n",
            "Phase val loss: 0.5910207320531209, acc: 0.6877333333333333\n",
            "Phase train loss: 0.5582576923915318, acc: 0.7174857142857143\n",
            "Phase val loss: 0.561030004342397, acc: 0.7193333333333334\n",
            "Phase train loss: 0.47706614756584165, acc: 0.7757142857142857\n",
            "Phase val loss: 0.5147122330665589, acc: 0.7484\n",
            "Period 3\n",
            "in_c:24 out_c:116 repeat_num:4\n",
            "in_c:116 out_c:232 repeat_num:8\n",
            "in_c:232 out_c:464 repeat_num:4\n",
            "in_c:24 out_c:116 repeat_num:4\n",
            "in_c:116 out_c:232 repeat_num:8\n",
            "in_c:232 out_c:464 repeat_num:4\n",
            "Phase train loss: 0.8034561254501342, acc: 0.5066285714285714\n",
            "Phase val loss: 0.69000676501592, acc: 0.5188\n",
            "Phase train loss: 0.6867967977660043, acc: 0.5382285714285714\n",
            "Phase val loss: 0.6641061104138692, acc: 0.5958666666666667\n",
            "Phase train loss: 0.6261146209444318, acc: 0.6536571428571428\n",
            "Phase val loss: 0.632522457520167, acc: 0.6666666666666666\n",
            "Phase train loss: 0.5564715722220285, acc: 0.7193142857142857\n",
            "Phase val loss: 0.5428179715156555, acc: 0.7248\n",
            "Phase train loss: 0.4826784296648843, acc: 0.7643428571428571\n",
            "Phase val loss: 0.4768300651550293, acc: 0.7692\n",
            "Period 4\n",
            "in_c:24 out_c:116 repeat_num:4\n",
            "in_c:116 out_c:232 repeat_num:8\n",
            "in_c:232 out_c:464 repeat_num:4\n",
            "in_c:24 out_c:116 repeat_num:4\n",
            "in_c:116 out_c:232 repeat_num:8\n",
            "in_c:232 out_c:464 repeat_num:4\n",
            "Phase train loss: 0.830773941394261, acc: 0.5048\n",
            "Phase val loss: 0.6980306694348654, acc: 0.5001333333333333\n",
            "Phase train loss: 0.6625157965523856, acc: 0.5892\n",
            "Phase val loss: 0.6064894587516785, acc: 0.6782666666666667\n",
            "Phase train loss: 0.5606525910990579, acc: 0.7156\n",
            "Phase val loss: 0.6032394945462545, acc: 0.7142666666666667\n",
            "Phase train loss: 0.474905553483963, acc: 0.7781142857142858\n",
            "Phase val loss: 0.45581717042922976, acc: 0.7833333333333333\n",
            "Phase train loss: 0.42137578888620647, acc: 0.8096\n",
            "Phase val loss: 0.46170552701950074, acc: 0.7790666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"training avg: { np.average(train_result)}\")\n",
        "print(f\"validation avg: { np.average(val_result)}\")\n"
      ],
      "metadata": {
        "id": "8E4YcnPFlNmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37ad3deb-f181-4f7d-ed6a-b6aee61bfbcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training avg: 0.7720685714285714\n",
            "validation avg: 0.7557600000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v64jXlOVnLM8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}